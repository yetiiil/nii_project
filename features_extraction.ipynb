{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from keras.models import Model\n",
    "from tensorflow.keras.utils import load_img\n",
    "from tqdm import tqdm\n",
    "\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(\"/Users/liyuxiao/Downloads/nii_project/dataset/1.json\")\n",
    "df[\"char\"] = df[\"data\"].apply(lambda x: x[\"char\"])\n",
    "df[\"url\"] = df[\"data\"].apply(\n",
    "    lambda x: \"/Users/liyuxiao/Downloads/nii_project/\" + x[\"url\"][28:]\n",
    ")\n",
    "df_count = (\n",
    "    df.groupby(\"char\").count().sort_values(by=[\"data\"], ascending=False)[[\"data\"]]\n",
    ")\n",
    "\n",
    "single_char = [ele for ele in df_count.index if len(ele) == 1]\n",
    "df_single_char = df[df[\"char\"].isin(single_char)]\n",
    "df_single_char.loc[:, \"image_file\"] = df_single_char[\"url\"].apply(lambda x: x[48:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"/Users/liyuxiao/Downloads/nii_project/dataset/1\"\n",
    "# change the working directory to the path where the images are located\n",
    "os.chdir(path)\n",
    "# this list holds all the image filename\n",
    "chars = []\n",
    "\n",
    "# creates a ScandirIterator aliased as files\n",
    "with os.scandir(path) as files:\n",
    "    # loops through each file in the directory\n",
    "    for file in files:\n",
    "        if (\n",
    "            file.name.endswith(\".jpg\")\n",
    "            and file.name in df_single_char[\"image_file\"].values\n",
    "        ):\n",
    "            # adds only the image files to the flowers list\n",
    "            chars.append(file.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n",
      "\n",
      "systemMemory: 8.00 GB\n",
      "maxCacheSize: 2.67 GB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-04 14:38:38.688353: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-04-04 14:38:38.688666: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "# load the model first and pass as an argument\n",
    "model = VGG16()\n",
    "model = Model(inputs=model.inputs, outputs=model.layers[-2].output)\n",
    "\n",
    "\n",
    "def extract_features(file, model):\n",
    "    # load the image as a 224x224 array\n",
    "    img = load_img(file, target_size=(224, 224))\n",
    "    # convert from 'PIL.Image.Image' to numpy array\n",
    "    img = np.array(img)\n",
    "    # reshape the data for the model reshape(num_of_samples, dim 1, dim 2, channels)\n",
    "    reshaped_img = img.reshape(1, 224, 224, 3)\n",
    "    # prepare image for model\n",
    "    imgx = preprocess_input(reshaped_img)\n",
    "    # get the feature vector\n",
    "    features = model.predict(imgx, use_multiprocessing=True, verbose=0)\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "p = r\"/Users/liyuxiao/Downloads/nii_project/dataset/2/char_features.pkl\"\n",
    "\n",
    "# lop through each image in the dataset\n",
    "for char in tqdm(chars):\n",
    "    # try to extract the features and update the dictionary\n",
    "    try:\n",
    "        feat = extract_features(\n",
    "            \"/Users/liyuxiao/Downloads/nii_project/dataset/2/\" + char, model\n",
    "        )\n",
    "        data[char] = feat\n",
    "    # if something fails, save the extracted features as a pickle file (optional)\n",
    "    except:\n",
    "        with open(p, \"wb\") as file:\n",
    "            pickle.dump(data, file)\n",
    "\n",
    "# get a list of the filenames\n",
    "filenames = np.array(list(data.keys()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/Users/liyuxiao/Downloads/nii_project/dataset/feature_data.pkl\", \"wb\") as fp:\n",
    "    pickle.dump(data, fp)\n",
    "    print(\"dictionary saved successfully to file\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nii",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
